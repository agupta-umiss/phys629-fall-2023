{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Phys 629, Fall 2023, University of Mississippi\n",
    "\n",
    "\n",
    "# Lecture 15, Chapter 5: Bayesian Statistical Inference\n",
    "\n",
    "Material in this lecture and notebook is based upon the Basic Stats portion of G. Richards' \"Astrostatistics\" class at Drexel University (PHYS 440/540, https://github.com/gtrichards/PHYS_440_540), the Introduction to Probability & Statistics portion of A. Connolly's & Ž. Ivezić's \"Astrostatistics & Machine Learning\" class at the University of Washington (ASTR 598, https://github.com/dirac-institute/uw-astr598-w18), J. Bovy's mini-course on \"Statistics & Inference in Astrophysics\" at the University of Toronto (http://astro.utoronto.ca/~bovy/teaching.html), and Stephen R. Taylor (https://github.com/VanderbiltAstronomy/astr_8070_s22). \n",
    "\n",
    "##### Reading:\n",
    "\n",
    "- [Textbook](http://press.princeton.edu/titles/10159.html) Chapter 5.\n",
    "- [David Hogg's \"Fitting A Model To Data\"](https://arxiv.org/abs/1008.4686)\n",
    "- [Jake VanderPlas's workshop \"Bayesian Astronomy\"](https://github.com/jakevdp/BayesianAstronomy)\n",
    "- [Jake VanderPlas's blog \"Frequentism and Bayesianism: A Practical Introduction\"](http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/)\n",
    "\n",
    "\n",
    "##### Highly recommended supplemental background reading:\n",
    "\n",
    "- [Jake VanderPlas: \"Frequentism and Bayesianism: A Python-driven Primer\"](https://arxiv.org/abs/1411.5018)\n",
    "- [Hogg, Bovy and Lang: \"Data analysis recipes: Fitting a model to data\"](https://arxiv.org/abs/1008.4686)\n",
    "\n",
    "\n",
    "##### For those who want to dive deep:\n",
    "\n",
    "- [D. Sivia and J. Skilling: \"Data Analysis: A Bayesian Tutorial\"](https://www.amazon.com/Data-Analysis-Bayesian-Devinderjit-Sivia/dp/0198568320)\n",
    "- [E.T. Jaynes: \"Probability Theory: The Logic of Science\"](http://bayes.wustl.edu/etj/prob/book.pdf)\n",
    "- [E.T. Jaynes: \"Confidence Intervals vs. Bayesian intervals\"](http://bayes.wustl.edu/etj/articles/confidence.pdf)\n",
    "- [This great explanation of confidence levels versus credible regions on Stackexchange](https://stats.stackexchange.com/questions/2272/whats-the-difference-between-a-confidence-interval-and-a-credible-interval/2287#2287)\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "* [From Bayes Rule To Bayesian Inference](#one)\n",
    "* [Bayesian Priors: What Are They & How Do I Choose Them?](#two)\n",
    "* [Bayesian Credible Regions](#three)\n",
    "* [Simple Parameter Estimation Examples](#four)\n",
    "\n",
    "\n",
    "***Exercises required for class participation are in <font color='red'>red</font>.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From \"Bayes Rule\" To \"Bayesian Inference\" <a class=\"anchor\" id=\"one\"></a>\n",
    "\n",
    "We had that \n",
    "\n",
    "$$p(x,y) = p(x|y)p(y) = p(y|x)p(x)$$\n",
    "\n",
    "We also used the notation for intersection ($p$ that both $A$ **and** $B$ will happen) \n",
    "\n",
    "$$p(A \\cap B) \\equiv p(A,B) = p(A|B)p(B) = p(B|A)p(A)$$\n",
    "\n",
    "We can define the **marginal probability** as\n",
    "\n",
    "$$p(x) = \\int p(x,y)dy,$$\n",
    "\n",
    "where **marginal means essentially projecting on to one axis**, and **conditional means taking a slice at a fixed value of one axis**.\n",
    "\n",
    "We can re-write this as\n",
    "\n",
    "$$p(x) = \\int p(x|y)p(y) dy$$\n",
    "\n",
    "Since $$p(x|y)p(y) = p(y|x)p(x)$$ we can write that\n",
    "\n",
    "$$p(y|x) = \\frac{p(x|y)p(y)}{p(x)} = \\frac{p(x|y)p(y)}{\\int p(x|y)p(y) dy}$$\n",
    "\n",
    "which in words says that\n",
    "\n",
    "> the (conditional) probability of $y$ given $x$ is just the (conditional) probability of $x$ given $y$ times the (marginal) probability of $y$ divided by the (marginal) probability of $x$, where the latter is just the integral of the numerator.\n",
    "\n",
    "This is **Bayes' rule**, which itself is not at all controversial, though its application can be as we'll discuss in detail. \n",
    "\n",
    "<font color='red'>Btw, what are the units of the various terms in the above expression? Discuss this with your colleagues.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recall Maximum Likelihood Estimation (MLE) applied to a Heteroscedastic Gaussian\n",
    "\n",
    "Assume $N$ measurements, $\\{x_i\\}$, where the uncertainty for each measurement is Gaussian with\n",
    "a known $\\sigma_i$. The likelihood of one measurement is \n",
    "\n",
    "$$L \\equiv p(x_i|\\mu,\\sigma_i) = \\frac{1}{\\sigma_i\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x_i-\\mu)^2}{2\\sigma_i^2}\\right).$$\n",
    "\n",
    "\n",
    "and therefore the likelihood of all N measurements is \n",
    "\n",
    "$$L \\equiv p(\\{x_i\\}|\\mu,\\sigma_i) = \\prod_{i=1}^N \\frac{1}{\\sigma_i\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x_i-\\mu)^2}{2\\sigma_i^2}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's draw a homoscedastic sample of $\\{x_i\\}$ from a Gaussian and see what happens with $L$. First generate a sample of $N$ points drawn from $\\mathcal{N}(\\mu,\\sigma)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "sampleSize = 3\n",
    "mu = 1.0\n",
    "sigma = 0.2 \n",
    "sample = norm(mu, sigma).rvs(sampleSize) \n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "As we did in the MLE lectures, let's now compute probabilities for each point centered at the measured value across a grid, and multiply the probabilities together to find the likelihood for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "muGrid = np.linspace(0,2,1000)\n",
    "\n",
    "L1 = norm(sample[0], sigma).pdf(muGrid) \n",
    "L2 = norm(sample[1], sigma).pdf(muGrid) \n",
    "L3 = norm(sample[2], sigma).pdf(muGrid) \n",
    "L = L1 * L2 * L3\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plt.plot(muGrid, L1, ls='-', c='green', \n",
    "         label=r'$L(x_1)$')\n",
    "plt.plot(muGrid, L2, ls='-', c='red', \n",
    "         label=r'$L(x_2)$')\n",
    "plt.plot(muGrid, L3, ls='-', c='blue', \n",
    "         label=r'$L(x_3)$')\n",
    "plt.plot(muGrid, L, ls='-', c='black', \n",
    "         label=r'$L(\\{x\\})$')\n",
    "\n",
    "plt.xlim(0.2, 1.8)\n",
    "plt.ylim(0, 8.0)\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.ylabel(r'$p(x_i|\\mu,\\sigma)$')\n",
    "plt.title('MLE for Gaussian Distribution')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>But what if I told you that mu>0.9? That's prior information! Complete and execute the following. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "muMin = 0.9\n",
    "L1[muGrid < ___] = ___\n",
    "L2[muGrid < ___] = ___\n",
    "L3[muGrid < ___] = ___\n",
    "L = ___ * ___ * ___\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "plt.plot(muGrid, L1, ls='-', c='green', label=r'$L(x_1)$')\n",
    "plt.plot(muGrid, L2, ls='-', c='red', label=r'$L(x_2)$')\n",
    "plt.plot(muGrid, L3, ls='-', c='blue', label=r'$L(x_3)$')\n",
    "plt.plot(muGrid, L, ls='-', c='black', label=r'$L(\\{x\\})$')\n",
    "\n",
    "plt.xlim(0.2, 1.8)\n",
    "plt.ylim(0, 8.0)\n",
    "plt.xlabel('$\\mu$')\n",
    "plt.ylabel(r'$p(x_i|\\mu,\\sigma)$')\n",
    "plt.title('MLE for Gaussian Distribution')\n",
    "plt.legend()\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Clearly the *maximum is unchanged in this trivial example*, but the distribution is truncated leading to very different uncertainty estimates than what one would naively get by assuming that all $\\mu$ values are equally likely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Essence of the Bayesian Method \n",
    "\n",
    "- The basic premise of the Bayesian method is that probability statements are not limited to data,  but can be made for model parameters and models themselves. \n",
    "- Inferences are made by producing  probability density functions (pdfs); most notably, **model parameters are treated as random variables**.\n",
    "- These **pdfs represent our \"belief spread\" in what the model parameters are**. They have nothing to do with outcomes of repeated experiments (although the shape of resulting distributions can often coincide).\n",
    "\n",
    "\n",
    "### Brief History \n",
    "\n",
    "- The **Reverend Thomas Bayes (1702–1761)** was an English amateur mathematician who wrote a manuscript \n",
    "on how to combine an initial belief with new data to arrive at an improved belief. \n",
    "- The manuscript \n",
    "was published posthumously in 1763 and gave rise to the name Bayesian statistics. \n",
    "- **Laplace** rediscovered the Bayesian approach a decade after it was originally published, and greatly clarified some principles.  \n",
    "- Howevever, Bayesian statistics did not find its ways into mainstream science until well into the 20th century, and widespread usage has been hindered until the 1990s with the advent of cheap computing that can map out the Bayesian probability distributions.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/d/d4/Thomas_Bayes.gif?1613667187659)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Statistical Inference\n",
    "\n",
    "Up to now we have been computing the **likelihood** $p(D\\,|\\,M)$.  In Bayesian inference, we instead evaluate the **posterior probability** taking into account **prior** information.\n",
    "\n",
    "Recall that Bayes' Rule is:\n",
    "\n",
    "$$p(M\\,|\\,D) = \\frac{p(D\\,|\\,M)\\,p(M)}{p(D)},$$\n",
    "\n",
    "where $D$ is for data and $M$ is for model. Or in words,\n",
    "\n",
    "$${\\rm Posterior \\,\\, Probability} = \\frac{{\\rm Likelihood}\\times{\\rm Prior}}{{\\rm Evidence}}.$$\n",
    "\n",
    "If we explicitly recognize prior information, $I$, and the model parameters, $\\theta$, then we can write:\n",
    "\n",
    "$$p(M,\\theta \\,|\\,D,I) = \\frac{p(D\\,|\\,M,\\theta,I)\\,p(M,\\theta\\,|\\,I)}{p(D\\,|\\,I)},$$\n",
    "\n",
    "where we will omit the explict dependence on $\\theta$ by writing $M$ instead of $M,\\theta$ where appropriate.  However, as the prior can be expanded to \n",
    "\n",
    "$$p(M,\\theta\\,|\\,I) = p(\\theta\\,|\\,M,I)\\,p(M\\,|\\,I),$$\n",
    "\n",
    "it will still appear in the term $p(\\theta\\,|\\,M,I)$.\n",
    "\n",
    "**NOTE** \n",
    "\n",
    "We don't often care about **the evidence $p(D\\,|\\,I)$** because it does not depend on model parameters. We usually set it to $1$ for parameter estimation. **BUT** it's at the heart of Bayesian model selection (which we'll look at in the future) since it gives us a way of ranking different model descriptions of the data.  \n",
    "\n",
    "**The Bayesian Statistical Inference process** is then\n",
    "1. formulate the likelihood, $p(D\\,|\\,M,\\theta,I)$\n",
    "2. choose a prior$^1$, $p(M,\\theta\\,|\\,I)$, which incorporates *other information beyond the data in $D$*\n",
    "3. determine the posterior pdf, $p(M,\\theta \\,|\\,D,I)$\n",
    "4. search for the model parameters that maximize $p(M,\\theta \\,|\\,D,I)$ \n",
    "5. quantify the uncertainty of the model parameter estimates\n",
    "6. perform model selection to find the most apt description of the data\n",
    " \n",
    "$^1$: Note that $p(M,\\theta\\,|\\,I) = p(\\theta\\,|\\,M, I)\\, p(M\\,|\\,I)$.  \n",
    "\n",
    "Before applying this expression, we need to discuss how to choose priors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian priors: What Are They & How Do I Choose Them? <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "Priors can be **informative** or **uninformative**.  As it sounds, informative priors are based on existing information (including previously obtained data, but not the data considered right now) that might be available.  Uniformative priors can be thought of as \"default\" priors, i.e., what your prior is when you never used\n",
    "any data, e.g, a \"flat\" prior like $p(\\theta|M,I) \\propto {\\rm C}$.\n",
    "\n",
    "Detailed discussion can be found in Section 5.2 in the textbook. In general, we want our inferences to be ***data dominated*** rather than prior dominated, so we try to use ***weakly-informative priors***. There are three\n",
    "main principles used to choose a prior: \n",
    "\n",
    "\n",
    "### (i) The Principle of Indifference\n",
    "\n",
    "Essentially this means adopting a uniform prior, though you have to be a bit careful.  Saying that an asteroid is equally likely to hit anywhere on the Earth is not the same as saying that all latitudes of impact are equally likely.  \n",
    "\n",
    "Assuming $1/6$ for a six-side die, or $1/2$ for heads and tails of a fair coin, would be an example of indifference.\n",
    "\n",
    "### (ii) The Principle of Invariance (or Consistency)\n",
    "\n",
    "This applies to location and scale invariance.  \n",
    "\n",
    "**Location invariance** suggests a uniform prior, within the accepted bounds: $p(\\theta|I) \\propto 1/(\\theta_{max}-\\theta_{min})$ for $\\theta_{min} \\le \\theta \\le \\theta_{max}$. \n",
    "\n",
    "**Scale invariance** gives us priors that look like $p(\\theta|I) \\propto 1/\\theta$, which implies a uniform\n",
    "prior for ln($\\theta$), i.e. a prior that gives equal weight over many orders of magnitude. \n",
    "\n",
    "### (iii) The Principle of Maximum Entropy\n",
    "\n",
    "We will not discuss it here - for more details, see Section 5.2.2 in the textbook.\n",
    " \n",
    "It is often true that Bayesian analysis and traditional MLE are essentially equivalent.  \n",
    "However, in some cases, considering the priors can have significant consequences, as\n",
    "we will see later. \n",
    "\n",
    "We will skip examples of very steep priors and their consequences called in astronomy\n",
    "literature **Eddington-Malmquist** and **Lutz-Kelker** biases (see Chapter 5 in the textbook\n",
    "if you are interested). \n",
    "\n",
    "### Conjugate Priors\n",
    "\n",
    "In special combinations of priors and likelihood functions, the resulting posterior probability distribution is from the same function family as the prior. These priors are called **conjugate priors** and give a convenient way for generalizing computations. There are exhaustive tables [here](https://www.wikiwand.com/en/Conjugate_prior#/Table_of_conjugate_distributions). \n",
    "\n",
    "**EXAMPLE**\n",
    "\n",
    "If the likelihood is Gaussian and the prior function is Gaussian, then so too is the posterior distribution! So the conjugate prior for a Gaussian likelihood is a Gaussian.\n",
    "\n",
    "For data drawn from a Gaussian likelihood equal to $\\mathcal{N}(\\bar{x},s)$ (where $\\bar{x}$ is the sample mean and $s$ is the sample standard deviation), with a prior on the underlying parameters $\\mathcal{N}(\\mu_p,\\sigma_p)$, the posterior is $\\mathcal{N}(\\mu^0,\\sigma^0)$, where\n",
    "\n",
    "$$\\mu^0 = \\frac{\\mu_p/\\sigma_p^2 + \\bar{x}/s^2}{1/\\sigma_p^2 + 1/s^2},\\quad \\sigma^0 = \\left( 1/\\sigma_p^2 + 1/s^2 \\right)^{-1/2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hierarchical Bayes\n",
    "\n",
    "You may hear of ***hierarchical Bayesian modeling*** a great deal these days. It's become sort of a buzz-term for people wanting to sound fancy, and [I am not immune to this](https://arxiv.org/abs/1806.08365). \n",
    "\n",
    "But there's nothing terribly fancy about it. Essentially, we will look at employing prior distributions today that have fixed shapes (e.g. Gaussian distributions centered around fixed values with fixed widths). \n",
    "\n",
    "But in hierarchical Bayesian modeling, the parameters of the prior distribution (called ***hyperparameters***) become part of the search! The data informs not only properties of individual events but also the shape of the prior. Those prior parameters then get their own priors, called ***hyperpriors***. \n",
    "\n",
    "**The whole analysis is then hierarchical, corresponding to multiple layers of inference.** \n",
    "\n",
    "For example, we have lots of [exoplanet discoveries](https://exoplanets.nasa.gov/discovery/discoveries-dashboard/). \n",
    "- Each of those discoveries started with some lightcurve data, where we fit a likelihood model to that data to deduce parameters of the system. \n",
    "- The prior on those parameters was likely weakly informative. \n",
    "- ***BUT*** the prior is really describing the underlying distribution of orbital periods, eccentricies, etc. So we can use our data not only to inform the properties of each system, but to map out the demographic distribution of exoplanet periods and more! Pretty cool! (e.g. https://arxiv.org/abs/1406.3020)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:phys629] *",
   "language": "python",
   "name": "conda-env-phys629-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
