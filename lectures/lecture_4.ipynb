{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Phys 629, Fall 2023, University of Mississippi\n",
    "\n",
    "\n",
    "# Lecture 4, Chapter 3: Probability and Statistical Distributions\n",
    "\n",
    "Material in this lecture and notebook is based upon the Basic Stats portion of G. Richards' \"Astrostatistics\" class at Drexel University (PHYS 440/540, https://github.com/gtrichards/PHYS_440_540), the Introduction to Probability & Statistics portion of A. Connolly's & Ž. Ivezić's \"Astrostatistics & Machine Learning\" class at the University of Washington (ASTR 598, https://github.com/dirac-institute/uw-astr598-w18), J. Bovy's mini-course on \"Statistics & Inference in Astrophysics\" at the University of Toronto (http://astro.utoronto.ca/~bovy/teaching.html), and Stephen R. Taylor (https://github.com/VanderbiltAstronomy/astr_8070_s22). \n",
    "\n",
    "##### Reading:\n",
    "\n",
    "- [Textbook](http://press.princeton.edu/titles/10159.html) Chapter 3. \n",
    "\n",
    "***Exercises required for class participation are in <font color='red'>red</font>.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Descriptive statistics <a class=\"anchor\" id=\"one\"></a>\n",
    "\n",
    "As we've said, our goal is to estimate $h(x)$ given some measured data, allowing us to reconstruct the data-based distribution $f(x)$. An arbitrary distribution can be characterized by **location** parameters (i.e., position), **scale** parameters (i.e., width), and **shape** parameters. These parameters are called ***descriptive statistics***.\n",
    "\n",
    "The distribution we're trying to characterize could be anything, e.g., (from my field) the distribution of masses of binary black-hole systems as discovered by gravitational-wave detectors. We really don't know the answer to this well, and the problem is made more complicated by things like detector selection effects (heavier systems are more likely to be observed), and blurring effects from measurement precision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "from astroML import stats as astroMLstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------------\n",
    "# Let's generate some data: a mix of several Cauchy distributions\n",
    "random_state = np.random.RandomState(seed=0)\n",
    "N = 10000\n",
    "mu_gamma_f = [(5, 1.0, 0.1),\n",
    "              (7, 0.5, 0.5),\n",
    "              (9, 0.1, 0.1),\n",
    "              (12, 0.5, 0.2),\n",
    "              (14, 1.0, 0.1)]\n",
    "hx = lambda x: sum([f * scipy.stats.cauchy(mu, gamma).pdf(x)\n",
    "                    for (mu, gamma, f) in mu_gamma_f])\n",
    "data = np.concatenate([scipy.stats.cauchy(mu, gamma).rvs(int(f * N), \n",
    "                                                         random_state=random_state)\n",
    "                       for (mu, gamma, f) in mu_gamma_f])\n",
    "random_state.shuffle(data)\n",
    "data = data[data > -10]\n",
    "data = data[data < 30]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# make a histogram to get an idea of what the distribution looks like\n",
    "plt.hist(data, bins=50, density=True, alpha=0.5);\n",
    "plt.xlabel('$x$');\n",
    "plt.ylabel('$f(x)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We all know that the **mean** of a sample is \n",
    "\n",
    "$$\\bar{x} = \\frac{1}{N}\\sum_{i=1}^N x_i$$ \n",
    "\n",
    "This is actually known as the **sample arithmetic mean**, and derives from *Monte Carlo integration* to get the first moment of the distribution, i.e. \n",
    "\n",
    "$$\\mu = E(x) = \\langle x \\rangle = \\int_{-\\infty}^{\\infty} x\\, h(x)\\,dx \\approx \\frac{1}{N}\\sum_{i=1}^N x_i $$\n",
    "\n",
    "where $\\{x_i\\}$ are random samples from the properly normalized $h(x)$, and $E(\\cdot)$ means the **expectation value**. In general we can use random sampling and Monte Carlo integration to deduce integrals over distributions such that \n",
    "\n",
    "$$\\int_{-\\infty}^{\\infty} g(x) h(x)\\,dx \\approx \\frac{1}{N}\\sum_{i=1}^N g(x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mean = np.mean(data)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "While it's most common to compute the mean, it may surprise you to learn that some distributions do not have formally calculable means (integration gives infinity). In these and other cases, the **median** is a more *robust* estimator of the (true) mean location of the distribution.  That's because it is less affected by **outliers**.\n",
    "\n",
    "To understand the previous statement, think about multiplying all numbers above the 50th percentile (i.e. the median) by 100, or even just replacing them with larger numbers. The mean would be strongly affected by these corrupted points, but **cumulative statistics based on the ordering of samples would remain unaffected by the outlier corruption**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell.  Think about and discuss what it is doing.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "median = np.median(data)\n",
    "\n",
    "mask = data > 15\n",
    "data2 = data.copy()\n",
    "data2[mask] = 100\n",
    "\n",
    "newmedian = np.median(data2)\n",
    "newmean = np.mean(data2)\n",
    "\n",
    "print(median, newmedian)\n",
    "print(mean, newmean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Repeat the above masking investigation, but this time multiply all samples above $15$ by a factor of 10. Do you get a similar effect?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other descriptive statistics are related to higher order moments of the distribution. Beyond the \"average\" *location* value, we'd like to know something about **deviations** from the average (which is related to the *shape* of the distribution).  The simplest thing to compute is deviation from mean $$d_i = x_i - \\mu.$$  However, the average deviation is zero by definition of the mean.  The next simplest thing to do is to compute the **mean absolute deviation (MAD)**:\n",
    "\n",
    "$$\\frac{1}{N}\\sum|x_i-\\mu|,$$\n",
    "\n",
    "but the absolute values can hide the true scatter of the distribution [in some cases (see here)](http://www.mathsisfun.com/data/standard-deviation.html).  So the next simplest thing to do is to square the differences $$\\sigma^2 = \\frac{1}{N}\\sum(x_i-\\mu)^2,$$ which we call the **variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The *variance* $V$ is just expectation value of $(x-\\mu)^2$ (and related to the 2nd moment)\n",
    "\n",
    "$$\\sigma^2 = V = E((x-\\mu)^2)\\int_{-\\infty}^{\\infty}  (x-\\mu)^2 h(x) dx,$$\n",
    "\n",
    "where $\\sigma$ is the **standard deviation**. Again, the integral gets replaced by a sum for discrete distributions. While most familiar for Gaussian distributions, you can compute the variance even if your distribution is not Gaussian.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "var = np.var(data)\n",
    "std = np.std(data)\n",
    "print(var, std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**$P\\%$ quantiles (or the $p^\\mathrm{th}$ percentile, $q_p$)** are computed as\n",
    "$$\\frac{p}{100} = H(q_p) = \\int_{-\\infty}^{q_p}h(x) dx$$\n",
    "\n",
    "The full integral from $-\\infty$ to $\\infty$ is 1 (100%).  So, here you are looking for the value of x that accounts for $p$ percent of the distribution.\n",
    "\n",
    "For example, the 25th, 50th, and 75th percentiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "q25, q50, q75 = np.percentile(data, [25, 50, 75])\n",
    "print(q25, q50, q75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The **interquartile range** is the difference between the 25th and 75th percentiles, $q_{75} - q_{25}$.\n",
    "\n",
    "Just as with the median, the interquartile range is a more *robust* estimator of the scale of a distribution than the standard deviation.  So, one can create a width estimater (at least for a Gaussian) from the interquartile range as\n",
    "\n",
    "$$\\sigma_G = 0.7413\\times(q_{75} - q_{25})$$  \n",
    "\n",
    "The normalization makes it *unbiased* for a perfect Gaussian (more on that later)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell. Think about and discuss the results.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from astroML import stats as astroMLstats\n",
    "\n",
    "# original data\n",
    "print(astroMLstats.sigmaG(data), np.std(data))\n",
    "\n",
    "# corrupted by outliers\n",
    "print(astroMLstats.sigmaG(data2), np.std(data2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell. Cumulative statistics take longer to compute, but are more robust.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%timeit np.mean(data), np.std(data)\n",
    "%timeit np.median(data), astroMLstats.sigmaG(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Make a plot of a histogram of the original data array, and add vertical lines at the 25th, 50th, and 75th percentiles.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The **mode** is the most probable value, determined from the peak of the distribution, which is the value where the derivative is 0 (i.e. the turning point):\n",
    "\n",
    "$$ \\left(\\frac{dh(x)}{dx}\\right)_{x_m} = 0$$\n",
    "\n",
    "Another way to estimate the mode (at least for a Gaussian distribution) is\n",
    "\n",
    "$$x_m = 3q_{50} - 2\\mu$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "mode = 3*q50 - 2*mean\n",
    "print(mode, mean, median)\n",
    "\n",
    "# Note: don't rely on scipy.stats.mode()\n",
    "# It gives the most common value of an array, \n",
    "# but we have a random sample of unique draws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Other useful ***shape*** measures include the \"higher order\" moments (the **skewness** and **kurtosis**):\n",
    "\n",
    "$$\\mathbf{Skewness}\\quad\\quad \\Sigma = \\int_{-\\infty}^{\\infty}  \\left(\\frac{x-\\mu}{\\sigma}\\right)^3 h(x) dx,$$\n",
    " \n",
    "$$\\mathbf{Kurtosis}\\quad\\quad K = \\int_{-\\infty}^{\\infty}  \\left(\\frac{x-\\mu}{\\sigma}\\right)^4 h(x) dx  - 3.$$\n",
    "\n",
    "The skewness measures the distribution's *asymmetry*. Distribution's with long tails to larger $x$ values have positive $\\Sigma$. \n",
    "\n",
    "The kurtosis measures how peaked or flat-topped a distribution is, with strongly peaked ones being positive and flat-topped ones being negative. $K$ is calibrated to a Gaussian distribution (hence the subtraction of $3$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![https://www.astroml.org/_images/fig_kurtosis_skew_1.png](https://www.astroml.org/_images/fig_kurtosis_skew_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "skew = scipy.stats.skew(data)\n",
    "kurt = scipy.stats.kurtosis(data)\n",
    "print(skew, kurt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Summary descriptive statistics for our distribution\n",
    "print(\"Location: \", mean, median, mode)\n",
    "print(\"Scale: \", var, std, astroMLstats.sigmaG(data))\n",
    "print(\"Shape: \", skew, kurt)\n",
    "print(\"Some percentiles: \", q25, q50, q75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "![Summary of various estimaters](figures/p8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample versus Population statistics <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "Statistics estimated from the *data* are called **sample statistics** as compared to **population statistics** derived from knowing the functional form of the pdf.\n",
    "\n",
    "Specifically, $\\mu$ is the **population mean**, i.e., it is the expecation value of $x$ for $h(x)$.  But we don't *know* $h(x)$.  So the **sample mean**, $\\overline{x}$, is an ***estimator*** of $\\mu$, defined as\n",
    "\n",
    "$$\\overline{x} \\equiv \\frac{1}{N}\\sum_{i=1}^N x_i,$$\n",
    "\n",
    "which we determine from the data itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Instead of the **population variance** $\\sigma^2$, we have the **sample variance**, $s^2$, where\n",
    "\n",
    "$$s^2 = \\frac{1}{N-1}\\sum_{i=1}^N(x_i-\\overline{x})^2$$\n",
    "\n",
    "The $N-1$ denominator (instead of $N$) accounts for the fact that we determine $\\overline{x}$ from the data itself instead of using a known $\\mu$. Ideally one tries to work in a regime where $N$ is large enough that we can be lazy and ignore this. \n",
    "\n",
    "So the mean and variance of a distribution are $\\mu$ and $\\sigma^2$.  The *estimators* of them are $\\overline{x}$ (or $\\hat{x}$) and $s^2$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uncertainty of sample statistics\n",
    "\n",
    "We would also like to know the uncertainty of our estimates $\\overline{x}$ and $s$.  Note that $s$ is the width estimate of the underlying distribution; it is **NOT** the uncertainty of $\\overline{x}$. Rather the uncertainty of $\\overline{x}$, $\\sigma_{\\overline{x}}$ is \n",
    "\n",
    "$$ \\sigma_{\\overline{x}} = \\frac{s}{\\sqrt{N}},$$\n",
    "\n",
    "which we call the **standard error of the mean**. The uncertainty of $s$ itself is\n",
    "\n",
    "$$\\sigma_s = \\frac{s}{\\sqrt{2(N-1)}} = \\frac{1}{\\sqrt{2}}\\sqrt{\\frac{N}{N-1}}\\sigma_{\\overline{x}}.$$\n",
    "\n",
    "Note that for large $N$, $\\sigma_{\\overline{x}} \\sim \\sqrt{2}\\sigma_s$ and for small $N$, $\\sigma_s$ is not much smaller than $s$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Summary of various estimaters](figures/p10.png)\n",
    "![Summary of various estimaters](figures/p11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Univariate distributions <a class=\"anchor\" id=\"three\"></a>\n",
    "\n",
    "If we are attempting to characterize our data in a way that is **parameterized**, then we need a functional form for a **distribution**.  There are many naturally occurring distributions.  The book goes through quite a few of them.  Here we'll just talk about a few basic ones to get us started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uniform Distribution\n",
    "\n",
    "The uniform distribution is perhaps more commonly called a \"top-hat\" or a \"box\" distribution.  It is specified by a mean, $\\mu$, and a width, $W$, where\n",
    "\n",
    "$$p(x|\\mu,W) = \\frac{1}{W}$$\n",
    "\n",
    "over the range $|x-\\mu|\\le \\frac{W}{2}$ and $0$ otherwise.  That says that \"given $\\mu$ AND $W$, the probability of $x$ is $\\frac{1}{W}$\" (as long as we are within a certain range).\n",
    "\n",
    "Since we are used to thinking of a Gaussian as the *only* type of distribution the concept of $\\sigma$ (aside from the width) may seem strange.  But $\\sigma$ as mathematically defined above applies here and\n",
    "$$\\sigma = \\frac{W}{\\sqrt{12}}.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell (don't worry about warnings)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Since you're working with a copy of my notebook, you\n",
    "# may need to change the path below to find the file\n",
    "%matplotlib inline\n",
    "%run ./scripts/fig_uniform_distribution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can implement [uniform](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html#scipy.stats.uniform) in `scipy` as follows.  We'll use the methods listed at the bottom of the link to complete the cell: `dist.rvs(size=N)` which produces `N` random draws from the distribution and `dist.pdf(x)` which returns the value of the pdf at a given $x$. Lots of distributions can be accessed and used in a similar way.  \n",
    "\n",
    "Create a uniform distribution with parameters `loc=0`,  `scale=2`, and `N=10`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Complete and execute the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "N = ____ # Complete\n",
    "distU = scipy.stats.uniform(____,____) # Complete\n",
    "draws = distU.rvs(____) # ten random draws\n",
    "print(draws)\n",
    "\n",
    "p = distU.pdf(____) # pdf evaluated at x=1\n",
    "\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gaussian Distribution\n",
    "\n",
    "As many of you know, the Gaussian distribution pdf is given by\n",
    "\n",
    "$$p(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "It is also called the **normal distribution** and can be noted by $\\mathscr{N}(\\mu,\\sigma)$.\n",
    "\n",
    "\n",
    "We love using Gaussians in physics and astronomy because they can approximate many distributions and are also super easy to work with. **The convolution of two Gaussians results in a Gaussian.**  So $\\mathscr{N}(\\mu_1,\\sigma_1)$ convolved with $\\mathscr{N}(\\mu_2,\\sigma_2)$ is $\\mathscr{N}(\\mu_1+\\mu_2,\\sqrt{\\sigma_1^2+\\sigma_2^2})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%run ./scripts/fig_gaussian_distribution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Uncomment the next line and run this cell; I just want you to know that this magic function exists.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../scripts/fig_gaussian_distribution.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Complete and execute the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "distG = scipy.stats.norm(____,____) # Normal distribution with mean = 100, stdev = 15\n",
    "draws = ____.____(____) # 10 random draws\n",
    "p = ____.____(____) # pdf evaluated at x=0\n",
    "\n",
    "print(draws)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Create a [normal distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html?highlight=stats%20norm#scipy.stats.norm) with `loc=100` and `scale=15`. Produce 10 random draws and determine the probability at `x=145`.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Make a plot of this Gaussian distribution. Plot the pdf from 0 to 200 with a 1000 gridpoints.</font>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Complete and execute the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Let's play with Gaussians! Or Normal distributions, N(mu,sigma)\n",
    "\n",
    "xgrid = np.linspace(____,____,____) # generate distribution for a uniform grid of x values\n",
    "____ = distG.pdf(____)  # this is a function of xgrid\n",
    "\n",
    "# actual plotting\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "\n",
    "# Python3 f strings are awesome!\n",
    "plt.plot(xgrid, gaussPDF, ls='-', c='black', \n",
    "         label=f'$\\mu={mu},\\ \\sigma={sigma}$')\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(0, 0.03)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\mu,\\sigma)$')\n",
    "plt.title('Gaussian Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cumulative distribution function, cdf is the integral of pdf from $x'=-\\infty$ to $x'=x$:\n",
    "\n",
    "$$\\mathrm{cdf}(x|\\mu,\\sigma) = \\int_{-\\infty}^{x} p(x'|\\mu,\\sigma) dx',$$\n",
    "\n",
    "where $\\mathrm{cdf}(\\infty) = 1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# The same as above but now with the cdf method\n",
    "gaussCDF = distG.cdf(xgrid)\n",
    "fig, ax = plt.subplots(figsize=(5, 3.75))\n",
    "plt.plot(xgrid, gaussCDF, ls='-', c='black', \n",
    "         label=r'$\\mu=%i,\\ \\sigma=%i$' % (mu, sigma))\n",
    "plt.xlim(0, 200)\n",
    "plt.ylim(-0.01, 1.01)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$CDF(x|\\mu,\\sigma)$')\n",
    "plt.title('Gaussian Distribution')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Gaussian confidence levels\n",
    "\n",
    "The probability of a measurement drawn from a Gaussian distribution that is between $\\mu-a$ and $\\mu+b$ is\n",
    "\n",
    "$$\\int_{\\mu-a}^{\\mu+b} p(x|\\mu,\\sigma) dx.$$\n",
    "\n",
    "- For $a=b=1\\sigma$, we get the familar result of 68.3%.  \n",
    "- For $a=b=2\\sigma$ it is 95.4%.  \n",
    "- For $a=b=3\\sigma$ it is $99.7\\%$. \n",
    "\n",
    "So we refer to the range $\\mu \\pm 1\\sigma$, $\\mu \\pm 2\\sigma$, and $\\mu \\pm 3\\sigma$ as the 68%, 95%, and $99.7%$ **confidence limits**, respectively. Note that if your distribution is not Gaussian, then these confidence intervals will be different!\n",
    "\n",
    "***We often still refer to uncertainty regions of distributions as $1\\sigma$ or $2\\sigma$ regions, which for non-Gaussian distributions usually means (for $1\\sigma$) the region enclosing the $16\\%$ and $84\\%$ quantiles.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>What is the probability enclosed between $-2\\sigma$ and $+4\\sigma$? (*Verify first that you get the correct answer for the bullet points above!*)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Complete and execute the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "N=10000\n",
    "mu=0\n",
    "sigma=1\n",
    "distN = ___.___.___(mu, sigma) # Complete\n",
    "xgrid = np.linspace(___,___,N) # Complete\n",
    "dx = (xgrid.max()-xgrid.min())/N\n",
    "prob = distN.pdf(xgrid)*dx\n",
    "\n",
    "print(prob.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We could do this in various ways. The way you just tried was the most obvious-- brute-force numerical integration with the trapezoidal method. \n",
    "\n",
    "But the clever way is to use the cdf, by computing the cdf of the upper integration bound and subtracting the cdf of the lower integration bound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Complete and execute the following cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "upper = distN.cdf(___)\n",
    "lower = distN.cdf(___)\n",
    "p = upper-lower\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log Normal\n",
    "\n",
    "Note that if $x$ is Gaussian distributed with $\\mathscr{N}(\\mu,\\sigma)$, then $y=\\exp(x)$ will have a **log-normal** distribution, where the mean of y is $\\exp(\\mu + \\sigma^2/2)$, the median is $\\exp(\\mu)$, and the mode is $\\exp(\\mu-\\sigma^2)$.  Try it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = scipy.stats.norm(0,1) # mean = 0, stdev = 1\n",
    "y = np.exp(x.rvs(100))\n",
    "\n",
    "print(y.mean())\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The catch here is that stats.norm(0,1) returns an *object* and not something that we can just do math on in the expected manner.  What *can* you do with it?  Try ```dir(x)``` to get a list of all the methods and properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Execute this cell\n",
    "distLN = scipy.stats.norm(0,1) # mean = 0, stdev = 1\n",
    "x = distLN.rvs(10000)\n",
    "y = np.exp(x)\n",
    "\n",
    "print(np.exp(0 + 0.5*1), y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Repeat the above calculations to verify the equations for the mode and median.</font>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:phys629] *",
   "language": "python",
   "name": "conda-env-phys629-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected",
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
