{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Phys 629, Fall 2023, University of Mississippi\n",
    "\n",
    "\n",
    "# Lecture 8, Chapter 4: Classical Statistical Inference\n",
    "\n",
    "Material in this lecture and notebook is based upon the Basic Stats portion of G. Richards' \"Astrostatistics\" class at Drexel University (PHYS 440/540, https://github.com/gtrichards/PHYS_440_540), the Introduction to Probability & Statistics portion of A. Connolly's & Ž. Ivezić's \"Astrostatistics & Machine Learning\" class at the University of Washington (ASTR 598, https://github.com/dirac-institute/uw-astr598-w18), J. Bovy's mini-course on \"Statistics & Inference in Astrophysics\" at the University of Toronto (http://astro.utoronto.ca/~bovy/teaching.html), and Stephen R. Taylor (https://github.com/VanderbiltAstronomy/astr_8070_s22). \n",
    "\n",
    "##### Reading:\n",
    "\n",
    "- [Textbook](http://press.princeton.edu/titles/10159.html) Chapter 4.\n",
    "\n",
    "***Exercises required for class participation are in <font color='red'>red</font>.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Statistical Inference <a class=\"anchor\" id=\"one\"></a>\n",
    "\n",
    "Statistical *inference* is about drawing conclusions from data, specifically determining the properties of a population by data sampling.\n",
    "\n",
    "Three examples of inference are:\n",
    "1. What is the best estimate for a model parameter?\n",
    "2. How confident are we about our result?\n",
    "3. Are the data consistent with a particular model/hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some Terminology\n",
    "\n",
    "* We typically study the properties of some ***population*** by measuring ***samples*** from that population. The population doesn't have to refer to different objects. E.g., we may be (re)measuring the position of an object at rest; the population is the distribution of (an infinite number of) measurements smeared by the uncertainty, and the sample are the measurement we've actually taken.\n",
    "\n",
    "\n",
    "* A ***statistic*** is any function of the sample. For example, the sample mean is a statistic. But also, \"the value of the first measurement\" is also a statistic. Don't stress too much about how to make a statistic; it's just a way of summarizing data in a way that helps reveal the presence of a signal. We will meet ways of finding the optimal statistic for a given scenario.\n",
    "\n",
    "\n",
    "* To conclude something about the population from the sample, we develop ***estimators***. An estimator is a statistic, a rule for calculating an estimate of a given quantity based on observed data.\n",
    "\n",
    "\n",
    "* There are ***point*** and ***interval estimators***. The point estimators yield single-valued results (example: the position of an object), while with an interval estimator, the result would be a range of plausible values (example: confidence interval for the position of an object).\n",
    "\n",
    "\n",
    "* Measurements have **uncertainties** (not errors) and we need to account for these (sometimes they are unknown). Data are not variables but fixed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Frequentist vs. Bayesian Inference\n",
    "\n",
    "There are two major statistical paradigms that address the statistical inference questions: \n",
    "- the **classical**, or **frequentist** paradigm,\n",
    "- the **Bayesian** paradigm.\n",
    "\n",
    "While most of statistics and machine learning is based on the classical paradigm, Bayesian techniques are being embraced by the statistical and scientific communities at an ever-increasing pace...especially in astrophysics.\n",
    "\n",
    "#### Key differences\n",
    "- **Definition of probabilities**:\n",
    "    - In ***frequentist inference***, probabilities describe the ***relative frequency of events*** over repeated experimental trials. \n",
    "    - In ***Bayesian infernece***, probabilities instead quantify our ***subjective belief about experimental outcomes, model parameters, or even models themselves***. \n",
    "    \n",
    "    \n",
    "- **Quantifying uncertainty**:\n",
    "    - In ***frequentist inference*** we have ***confidence levels*** that describe the distribution of the measured parameter from the data around the true value.\n",
    "    - In ***Bayesian inference*** we have ***credible regions*** derived from posterior probabilitiy distributions (we'll meet these later). These encode our \"***belief spread***\" in model parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "Let's say that you get the results of an IQ test.  Any given test result might not give you your \"real\" IQ (whatever that means anyway...).  But it gives us a way to *estimate* it (and the possible range of values).  \n",
    "- For a frequentist, the best estimator is the average of many test results.  So, if you took 5 IQ tests and got a sample mean of 160, then that would be the estimator of your true IQ.\n",
    "- On the other hand, a Bayesian would say: \"*but wait, I know that IQ tests are calibrated to have a mean of 100 with a standard deviation of 15 points*\".  So they will use that as \"prior\" information, which is important here since 160 is a 4$\\sigma$ outlier. \n",
    "\n",
    "There's nothing mysterious about priors. It simply encodes any previous knowledge or information we have about our experiment.\n",
    "\n",
    "The following article provides a nice example that is visualized below (without the detailed math) [Efron 1978](http://www.jstor.org/stable/2321163?seq=1#page_scan_tab_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'># Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import scipy.stats\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import uniform\n",
    "from astroML import stats as astroMLstats\n",
    "\n",
    "#from astroML.plotting import setup_text_plots\n",
    "#setup_text_plots(fontsize=10, usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Complete and execute the following cell. It will show the simple average of IQ tests, the prior distribution one would use in a Bayesian analysis, and the final Bayesian posterior \"belief\" distribution.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Define the distributions to be plotted\n",
    "sigma_values = [___, 6.7, 1] #complete with the prior width of IQ distribution\n",
    "linestyles = ['--', '-', ':']\n",
    "mu_values = [____, 148, 160] #complete with the prior mean of IQ distribution\n",
    "labeltext = ['prior dist.', \n",
    "             'posterior dist.', \n",
    "             'observed mean']\n",
    "xplot = np.linspace(50, 200, 1000)\n",
    "\n",
    "#------------------------------------------------------------\n",
    "# plot the distributions\n",
    "fig, ax = plt.subplots(figsize=(10, 7.5))\n",
    "\n",
    "for sigma, ls, mu, lab in zip(sigma_values, \n",
    "                              linestyles, \n",
    "                              mu_values, \n",
    "                              labeltext):\n",
    "    \n",
    "    # create a gaussian / normal distribution\n",
    "    dist = norm(mu, sigma)\n",
    "\n",
    "    if sigma > 1:\n",
    "        plt.plot(xplot, dist.pdf(xplot), \n",
    "                 ls=ls, c='black',\n",
    "                 label=r'%s $\\mu=%i,\\ \\sigma=%.1f$' % (lab, mu, sigma))\n",
    "    else:\n",
    "        plt.plot([159.9, 160.1], [0, 0.8], \n",
    "                 ls=ls, color='k', label=r'%s $\\mu=%i$' % (lab, mu))\n",
    "        \n",
    "plt.xlim(50, 200)\n",
    "plt.ylim(0, 0.1)\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\mu,\\sigma)$')\n",
    "plt.title('Gaussian Distribution')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The end result (skipping over the detailed math) is that the Bayesian estimate of the IQ is not 160, but rather 148, or more specifically that $p(141.3\\le \\mu \\le 154.7 \\, | \\, \\overline{x}=160) = 0.683$. This estimate incorporates the prior information of how the IQ distribution is calibrated.\n",
    "\n",
    "This all seems totally fine; where's the controvery with Bayesian methods? The controvery arises when we don't know the prior distribution, or when the parameter is fixed but we are trying to experimentally verify it (e.g., the speed of light). We'll return to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximum Likelihood Estimation (MLE) <a class=\"anchor\" id=\"two\"></a>\n",
    "\n",
    "Let's talk about maximum likelihood estimation ($\\S 4.2$ in the textbook), which is relevant to both Bayesian and Frequentist approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood Approach\n",
    "\n",
    "Maximum likelihood estimation follows this blueprint:\n",
    "\n",
    "1. **Hypothesis**: Formulate a model, a *hypothesis*, about how the data are generated. For example, the data are a measurement of some quantity with Gaussian random uncertainties (i.e., each measurement is equal to the true value, plus a deviation randomly drawn from the normal distribution). Models are typically described using a set of model parameters $\\boldsymbol{\\theta}$, and written as $\\boldsymbol{M}(\\boldsymbol{\\theta})$.\n",
    "\n",
    "\n",
    "2. **Maximum Likelihood Estimation**: Search for the \"best\" model parameters $\\boldsymbol{\\theta}$ which maximize the ***likelihood*** $L(\\boldsymbol{\\theta}) \\equiv p(D|M)$. This search yields the MLE *point estimates*, $\\boldsymbol{\\theta^0}$.\n",
    "\n",
    "\n",
    "3. **Quantifying Estimate Uncertainty**: Determine the confidence region for model parameters, $\\boldsymbol{\\theta^0}$. Such a confidence estimate can be obtained analytically (possibly with some approximations), but can also be done numerically for arbitrary models using general frequentist techniques, such as bootstrap, jackknife, and cross-validation (we'll come to these later).\n",
    "\n",
    "\n",
    "4. **Hypothesis Testing**: Perform hypothesis tests as needed to make other conclusions about models and point estimates. Possibly GOTO #1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Measuring the Position of a Quasar\n",
    "\n",
    "Let's assume we wish to estimate the position $x$ of a quasar from a series of individual astrometric measurements.\n",
    "\n",
    "1. We adopt a model where the observed quasar does not move, and has individual measurement uncertainties \n",
    "2. We derive the expression for the likelihood of there being a quasar at position $x_0$ that gives rise to our individual measurements. We find the value of $\\hat x_0$ for which our observations are maximally likely.\n",
    "3. We determine the uncertainties (confidence intervals) on our measurement.\n",
    "4. We test whether what we've observed is consistent with our adopted model. For example, is it possible that the quasar was really a misidentified star with measurable proper motion?\n",
    "\n",
    "Note: in the text to come, we will use $\\mu$ instead of $x_0$ to denote the true position of the quasar. This is to avoid potential confusion with the first (or zeroth) measurement of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'>Stop here for a minute and talk with your colleagues. What likelihood function would you choose as an approximation for this situation? What underlying assumptions did you make?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Likelihood Function\n",
    "\n",
    "If we know the distribution from which our data were drawn (or make a hypothesis about it), then we can compute the **probability** of our data being generated.\n",
    "\n",
    "For example, if our data are generated by a Gaussian process with mean $\\mu$ and standard deviation $\\sigma$, then the probability density of a certain value $x$ is\n",
    "\n",
    "$$p(x|\\mu,\\sigma) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x-\\mu)^2}{2\\sigma^2}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<font color='red'># Execute this cell</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the distributions\n",
    "fig, ax = plt.subplots(figsize=(10, 7.5))\n",
    "dist = norm(5, 1)\n",
    "x = np.linspace(0, 10, 1000)\n",
    "plt.plot(x, dist.pdf(x), c='black',label=r'$\\mu=5,\\ \\sigma=1$')\n",
    "\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 0.5)\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel(r'$p(x|\\mu=5,\\sigma=1)$')\n",
    "plt.title('Probability of $x$')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# useful to know you can do this...\n",
    "norm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If we want to know the total probability of our ***entire*** data set (as opposed to one measurement) then we must compute the ***product*** of all the individual probabilities:\n",
    "\n",
    "$$L \\equiv p(\\{x_i\\}|M(\\theta)) = \\prod_{i=1}^N p(x_i|M(\\theta)),$$\n",
    "\n",
    "where $M$ is the *model* and $\\theta$ refers collectively to the $k$ parameters of the model, which can generally be multi-dimensional. In words...\n",
    "\n",
    "> $L(\\{x_i\\})\\equiv$ the probability of the data given the model parameters. \n",
    "\n",
    "If we consider $L$ as a function of the model parameters, we refer to it as\n",
    "\n",
    "> $L(\\theta)\\equiv$ likelihood of the model parameters, given the observed data. \n",
    "\n",
    "Note:\n",
    "- [Jeynes](https://www.amazon.com/Probability-Theory-Science-T-Jaynes/dp/0521592712) is quite strict on how refer to the likelihood of model parameters versus the probability of the data, but we'll be a bit more lax.\n",
    "- while the components of $L$ may be normalized pdfs, their product is not.\n",
    "- the product can be very small, so we often take the log of $L$. \n",
    "- we're assuming the individual measurements are independent of each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can write $L$ out as\n",
    "\n",
    "$$L = \\prod_{i=1}^N \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(\\frac{-(x_i-\\mu)^2}{2\\sigma^2}\\right),$$\n",
    "\n",
    "and simplify to\n",
    "\n",
    "$$L = \\left( \\prod_{i=1}^N \\frac{1}{\\sigma\\sqrt{2\\pi}} \\right) \\exp\\left( -\\frac{1}{2} \\sum \\left[\\frac{-(x_i-\\mu)}{\\sigma} \\right]^2 \\right),$$\n",
    "\n",
    "where we have written the ***product of the exponentials as the exponential of the sum of the arguments***, which will make things easier to deal with later.\n",
    "\n",
    "To repeat, all we have done is this: \n",
    "\n",
    "$$\\prod_{i=1}^N A_i \\exp(-B_i) = (A_iA_{i+1}\\ldots A_N) \\exp[-(B_i+B_{i+1}+\\ldots+B_N)]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you have done $\\chi^2$ analysis (e.g., doing a linear least-squares fit), then you might notice that the argument of the exponential is just \n",
    "\n",
    "$$\\exp \\left(-\\frac{\\chi^2}{2}\\right).$$\n",
    "\n",
    "That is, for our gaussian distribution\n",
    "\n",
    "$$\\chi^2 = \\sum_{i=1}^N \\left ( \\frac{x_i-\\mu}{\\sigma}\\right)^2.$$\n",
    "\n",
    "So, **maximizing the likelihood or log-likelihood is the same as minimizing $\\chi^2$**.  In both cases we are finding the most likely values of our model parameters (here $\\mu$ and $\\sigma$).  "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
