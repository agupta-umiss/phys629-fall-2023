{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phys 629: Statistical Tools for Physics Research\n",
    "***Anuradha Gupta***\n",
    "\n",
    "# Homework 5\n",
    "### Due: Friday, Oct 6 at 11:59 pm CT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "This week we have only one problem worth 20 points. This problem uses a dataset in `/coursework/homeworks/hw_data/`.\n",
    "\n",
    "1) Read in `hw5_data.npy`. This is a (50 x 2) numpy array, with measurements in the first column and uncertainties in the second column. Using the analytic results for heteroscedastic Gaussian data from lectures, compute the sample mean and the standard error on the sample mean from for this data.\n",
    "\n",
    "2) Reusing some approaches and tools from `lecture_11`, write a ln-likelihood function for heteroscedastic Gaussian data, and use it in a fitting algorithm to find the best-fit mean. *Remember that scipy optimizers are set up to minimize functions.*\n",
    "\n",
    "3) Using the same numerical technique from `lecture_10`, compute the Fisher uncertainty estimate on the mean.\n",
    "\n",
    "4) While we have fitted a heteroscedastic Gaussian to this data, let's try something else. Write some code to define a ln-likelihood for a Laplace distribution evaluated on this data. Fit simultaneously for the Laplace location parameter $\\mu$ and scale parameter $\\Delta$.\n",
    "\n",
    "5) Compute the AIC values for the heteroscedastic Gaussian model and the Laplacian model. Which model is favored by the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Load the .npy file\n",
    "data = np.load('hw5_data.npy')\n",
    "\n",
    "# Create a DataFrame and specify column names\n",
    "df = pd.DataFrame(data, columns=['measurements', 'uncertainties'])\n",
    "\n",
    "# Now, 'df' is a DataFrame with named columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measurements</th>\n",
       "      <th>uncertainties</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.972077</td>\n",
       "      <td>0.938065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.988243</td>\n",
       "      <td>1.402627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.669820</td>\n",
       "      <td>1.971207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.965197</td>\n",
       "      <td>0.603593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.385415</td>\n",
       "      <td>1.296987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4.077840</td>\n",
       "      <td>1.442946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>4.101358</td>\n",
       "      <td>1.939565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3.080222</td>\n",
       "      <td>1.012284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4.536944</td>\n",
       "      <td>1.923794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3.198800</td>\n",
       "      <td>1.050583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    measurements  uncertainties\n",
       "0       2.972077       0.938065\n",
       "1       1.988243       1.402627\n",
       "2       1.669820       1.971207\n",
       "3       3.965197       0.603593\n",
       "4       3.385415       1.296987\n",
       "..           ...            ...\n",
       "95      4.077840       1.442946\n",
       "96      4.101358       1.939565\n",
       "97      3.080222       1.012284\n",
       "98      4.536944       1.923794\n",
       "99      3.198800       1.050583\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.1 Computing the sample mean and the standard error on the sample mean </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE for mean (mu_hat): 3.917992035\n",
      "Uncertainty of the mean (sigma_mu): 0.094810841\n"
     ]
    }
   ],
   "source": [
    "#Extract the 'measurements' and 'uncertainties' columns\n",
    "\n",
    "measurements = df['measurements']\n",
    "uncertainties = df['uncertainties']\n",
    "\n",
    "# Calculate the MLE for the mean (mu_hat)\n",
    "mu_hat = np.sum(measurements / uncertainties**2) / np.sum(1 / uncertainties**2)\n",
    "\n",
    "# Calculate the uncertainty of the mean (sigma_mu)\n",
    "sigma_mu = 1 / np.sqrt(np.sum(1 / uncertainties**2))\n",
    "\n",
    "print(f\"MLE for mean (mu_hat): {mu_hat:.9f}\")\n",
    "print(f\"Uncertainty of the mean (sigma_mu): {sigma_mu:.9f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.2 Best fit $\\mu$ </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-fit mean (mu): 3.917992028\n"
     ]
    }
   ],
   "source": [
    "import scipy.optimize as opt\n",
    "\n",
    "# Define the negative log-likelihood function\n",
    "def neg_log_likelihood(mu, x, sigma):\n",
    "    residuals = (x - mu) ** 2 / sigma**2 + np.log(sigma**2)\n",
    "    return 0.5 * np.sum(residuals)\n",
    "\n",
    "# Initial guess for the mean (mu)\n",
    "initial_guess = np.mean(measurements)\n",
    "\n",
    "# Minimize the negative log-likelihood to find the best-fit mean (mu)\n",
    "result = opt.minimize(neg_log_likelihood, initial_guess, args=(measurements, uncertainties))\n",
    "\n",
    "# Extract the best-fit mean from the result\n",
    "best_fit_mean = result.x[0]\n",
    "\n",
    "print(f\"Best-fit mean (mu): {best_fit_mean:.9f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.3 Fisher uncertainty estimate </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fisher uncertainty estimate on the mean (sigma_mu): 0.094810841\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute the Fisher Information Matrix (FIM)\n",
    "def compute_fisher_information(mu, x, sigma):\n",
    "    n = len(x)\n",
    "    FIM = np.zeros((1, 1))  # Initialize a 1x1 matrix for the Fisher Information Matrix\n",
    "    for i in range(n):\n",
    "        term = 1 / sigma[i]**2\n",
    "        FIM += term\n",
    "    return FIM\n",
    "\n",
    "FIM = compute_fisher_information(best_fit_mean, measurements, uncertainties)\n",
    "\n",
    "# Compute the Fisher uncertainty estimate on the mean (sigma_mu)\n",
    "sigma_mu = np.sqrt(np.linalg.inv(FIM)[0, 0])\n",
    "\n",
    "\n",
    "print(f\"Fisher uncertainty estimate on the mean (sigma_mu): {sigma_mu:.9f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.4 Laplace Log-Likelihood </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLE for Laplace location parameter (mu): 4.085951634\n",
      "MLE for Laplace scale parameter (delta): 0.882269239\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the negative log-likelihood function for Laplace distribution\n",
    "def neg_log_likelihood(params, x):\n",
    "    mu, delta = params\n",
    "    n = len(x)\n",
    "    log_likelihood = -n * np.log(2 * delta) - np.sum(np.abs(x - mu) / delta)\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization\n",
    "\n",
    "\n",
    "\n",
    "# Initial guesses for parameters (mu and delta)\n",
    "initial_guess = [np.mean(measurements), np.std(measurements)]\n",
    "\n",
    "# Minimize the negative log-likelihood to find MLEs of parameters (mu and delta)\n",
    "result = opt.minimize(neg_log_likelihood, initial_guess, args=(measurements,))\n",
    "\n",
    "# Extract the MLEs of parameters (mu and delta) from the result\n",
    "mu_mle, delta_mle = result.x\n",
    "\n",
    "print(f\"MLE for Laplace location parameter (mu): {mu_mle:.9f}\")\n",
    "print(f\"MLE for Laplace scale parameter (delta): {delta_mle:.9f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1.5 </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC for Laplace Model: 317.7015\n",
      "AIC for Gaussian Model: 112.7688\n",
      "The Gaussian model is favored by the data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the negative log-likelihood function for the Laplace distribution\n",
    "def neg_log_likelihood_laplace(params, x):\n",
    "    mu, delta = params\n",
    "    n = len(x)\n",
    "    log_likelihood = -n * np.log(2 * delta) - np.sum(np.abs(x - mu) / delta)\n",
    "    return -log_likelihood  # Return negative log-likelihood for minimization\n",
    "\n",
    "\n",
    "# Define the negative log-likelihood function for heteroscedastic Gaussian distribution\n",
    "def neg_log_likelihood_gaussian(params, x, sigma):\n",
    "    mu, = params\n",
    "    residuals = (x - mu) ** 2 / sigma**2 + np.log(sigma**2)\n",
    "    return 0.5 * np.sum(residuals)\n",
    "\n",
    "\n",
    "\n",
    "# Initial guesses for parameters (mu and delta) for Laplace model\n",
    "initial_guess_laplace = [np.mean(measurements), np.std(measurements)]\n",
    "\n",
    "# Initial guess for parameter (mu) for Gaussian model\n",
    "initial_guess_gaussian = [np.mean(measurements)]\n",
    "\n",
    "\n",
    "\n",
    "# Minimize the negative log-likelihood to find MLEs of parameters for Laplace model\n",
    "result_laplace = opt.minimize(neg_log_likelihood_laplace, initial_guess_laplace, args=(measurements,))\n",
    "\n",
    "# Minimize the negative log-likelihood to find MLEs of parameter for Gaussian model\n",
    "result_gaussian = opt.minimize(neg_log_likelihood_gaussian, initial_guess_gaussian, args=(measurements, uncertainties))\n",
    "\n",
    "\n",
    "\n",
    "# Extract the MLEs of parameters for Laplace model (mu and delta) from the result\n",
    "mu_mle_laplace, delta_mle = result_laplace.x\n",
    "\n",
    "# Extract the MLE of parameter for Gaussian model (mu) from the result\n",
    "mu_mle_gaussian = result_gaussian.x[0]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the maximum log-likelihood for both models\n",
    "max_log_likelihood_laplace = -neg_log_likelihood_laplace(result_laplace.x, measurements)\n",
    "max_log_likelihood_gaussian = -neg_log_likelihood_gaussian(result_gaussian.x, measurements, uncertainties)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the number of parameters for each model\n",
    "k_laplace = 2  # Laplace model has two parameters (mu and delta)\n",
    "k_gaussian = 1  # Gaussian model has one parameter (mu)\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the AIC values for both models\n",
    "N = len(measurements)\n",
    "aic_laplace = -2 * max_log_likelihood_laplace + 2 * k_laplace + (2 * k_laplace * (k_laplace + 1)) / (N - k_laplace - 1)\n",
    "aic_gaussian = -2 * max_log_likelihood_gaussian + 2 * k_gaussian + (2 * k_gaussian * (k_gaussian + 1)) / (N - k_gaussian - 1)\n",
    "\n",
    "print(f\"AIC for Laplace Model: {aic_laplace:.4f}\")\n",
    "print(f\"AIC for Gaussian Model: {aic_gaussian:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Compare AIC values and determine which model is favored\n",
    "if aic_laplace < aic_gaussian:\n",
    "    print(\"The Laplace model is favored by the data.\")\n",
    "else:\n",
    "    print(\"The Gaussian model is favored by the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
